{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASPNHSUS</th>\n",
       "      <th>UNRATE_x</th>\n",
       "      <th>UNRATE_y</th>\n",
       "      <th>USACPIHOUMINMEI_x</th>\n",
       "      <th>USACPIHOUMINMEI_y</th>\n",
       "      <th>CSUSHPINSA_x</th>\n",
       "      <th>CSUSHPINSA_y</th>\n",
       "      <th>MSPNHSUS</th>\n",
       "      <th>MSACSR</th>\n",
       "      <th>MORTGAGE30US_x</th>\n",
       "      <th>MORTGAGE30US_y</th>\n",
       "      <th>NHFSEPUC</th>\n",
       "      <th>NHSDPC</th>\n",
       "      <th>NHSDPNS</th>\n",
       "      <th>HNFSEPUSSA</th>\n",
       "      <th>HSN1F</th>\n",
       "      <th>DSPIC96_x</th>\n",
       "      <th>DSPIC96_y</th>\n",
       "      <th>DATE</th>\n",
       "      <th>TOTALSA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ASPNHSUS, UNRATE_x, UNRATE_y, USACPIHOUMINMEI_x, USACPIHOUMINMEI_y, CSUSHPINSA_x, CSUSHPINSA_y, MSPNHSUS, MSACSR, MORTGAGE30US_x, MORTGAGE30US_y, NHFSEPUC, NHSDPC, NHSDPNS, HNFSEPUSSA, HSN1F, DSPIC96_x, DSPIC96_y, DATE, TOTALSA]\n",
       "Index: []"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find all names of our data files in csv format (all csv data has the format of 2 columns, 1st column being DATE, \n",
    "# Second column being the feature we believe that is important for our model). In order to merge all these seperate\n",
    "# featrue values into a single csv (pandas DataFrame) file for futher data cleaning and processing before the modeling,\n",
    "# phase, we loop through all the file names (saved into a list) and reading them into the pandas DataFrame one at a \n",
    "# time while joining them based on the \"DATE\" column.\n",
    "\n",
    "# Initialize an empty DataFrame object to build up into a complete dataframe with all needed features through merging other feature dataframes\n",
    "df = pd.DataFrame()\n",
    "# locate the directory path where the data are located on the local machine\n",
    "wd = os.path.abspath('FeatureData')\n",
    "# find all the data in csv format under the located directory and save them as a list variable\n",
    "all_files = glob.glob(wd + '/*.csv')\n",
    "# Open all the csv feature data as a Pandas DataFrame and saving it inside a list variable\n",
    "df_list = [pd.read_csv(file) for file in all_files]\n",
    "# Merge all feature dataframes into one single Pandas DataFrame (The previous intialized DataFrame)\n",
    "df = reduce(lambda df1, df2: pd.merge(df1,df2,on=\"DATE\"), df_list)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the fact that the \"DATE\" column's format in different feature csv data being different from different online sources, the above merge would not be able to happen properly, resulting the dataframe to only have the merged column names but no tuple data rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASPNHSUS</th>\n",
       "      <th>UNRATE</th>\n",
       "      <th>USACPIHOUMINMEI</th>\n",
       "      <th>CSUSHPINSA</th>\n",
       "      <th>MSPNHSUS</th>\n",
       "      <th>MSACSR</th>\n",
       "      <th>MORTGAGE30US</th>\n",
       "      <th>NHFSEPUC</th>\n",
       "      <th>NHSDPC</th>\n",
       "      <th>NHSDPNS</th>\n",
       "      <th>HNFSEPUSSA</th>\n",
       "      <th>HSN1F</th>\n",
       "      <th>DSPIC96</th>\n",
       "      <th>TOTALSA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>144200.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>59.963759</td>\n",
       "      <td>75.697</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>8.4320</td>\n",
       "      <td>131.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>281.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>6616.3</td>\n",
       "      <td>12.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144800.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>60.195578</td>\n",
       "      <td>75.652</td>\n",
       "      <td>117200.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>8.7625</td>\n",
       "      <td>129.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>639.0</td>\n",
       "      <td>6649.9</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>144800.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>60.466033</td>\n",
       "      <td>75.812</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>8.9350</td>\n",
       "      <td>135.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>553.0</td>\n",
       "      <td>6659.6</td>\n",
       "      <td>12.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>145000.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>60.388760</td>\n",
       "      <td>76.079</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>8.8525</td>\n",
       "      <td>134.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>274.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>6679.4</td>\n",
       "      <td>12.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>146000.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>60.350123</td>\n",
       "      <td>76.398</td>\n",
       "      <td>113000.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.6720</td>\n",
       "      <td>135.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>554.0</td>\n",
       "      <td>6712.9</td>\n",
       "      <td>13.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ASPNHSUS  UNRATE  USACPIHOUMINMEI  CSUSHPINSA  MSPNHSUS  MSACSR  \\\n",
       "0  144200.0     7.3        59.963759      75.697  120000.0     5.2   \n",
       "1  144800.0     7.4        60.195578      75.652  117200.0     4.9   \n",
       "2  144800.0     7.4        60.466033      75.812  120000.0     6.1   \n",
       "3  145000.0     7.4        60.388760      76.079  120000.0     6.1   \n",
       "4  146000.0     7.6        60.350123      76.398  113000.0     6.0   \n",
       "\n",
       "   MORTGAGE30US  NHFSEPUC  NHSDPC  NHSDPNS  HNFSEPUSSA  HSN1F  DSPIC96  \\\n",
       "0        8.4320     131.0    16.0     17.0       281.0  676.0   6616.3   \n",
       "1        8.7625     129.0    16.0     20.0       269.0  639.0   6649.9   \n",
       "2        8.9350     135.0    16.0     20.0       279.0  553.0   6659.6   \n",
       "3        8.8525     134.0    14.0     17.0       274.0  546.0   6679.4   \n",
       "4        8.6720     135.0    16.0     18.0       273.0  554.0   6712.9   \n",
       "\n",
       "   TOTALSA  \n",
       "0     12.6  \n",
       "1     12.9  \n",
       "2     12.8  \n",
       "3     12.6  \n",
       "4     13.1  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Thus, the following is a new way of joining our data into one single dataframe object.\n",
    "# Find all names of our data files in csv format (all csv data has the format of 2 columns, 1st column being DATE, \n",
    "# Second column being the feature we believe that is important for our model). In order to merge all these seperate\n",
    "# featrue values into a single csv (pandas DataFrame) file for futher data cleaning and processing before the modeling,\n",
    "# phase, we loop through all the file names (saved into a list) and reading them into the pandas DataFrame one at a \n",
    "# time while joining them based on the \"DATE\" column.\n",
    "\n",
    "# Initialize an empty DataFrame object to build up into a complete dataframe with all needed features through merging other feature dataframes\n",
    "df = pd.DataFrame()\n",
    "# locate the directory path where the data are located on the local machine\n",
    "wd = os.path.abspath('FeatureData')\n",
    "# find all the data in csv format under the located directory and save them as a list variable\n",
    "all_files = glob.glob(wd + '/*.csv')\n",
    "# Open all the csv feature data as a Pandas DataFrame and saving it inside a list variable\n",
    "df_list = [pd.read_csv(file) for file in all_files]\n",
    "# Expand the initialized DataFrame by assigning it the second column of all the feature data file as a new column\n",
    "# omitting the DATE column to avoid problems caused by different DATE format\n",
    "for fileIndex in range(len(df_list)):\n",
    "    df[df_list[fileIndex].columns[1]] = df_list[fileIndex][df_list[fileIndex].columns[1]]\n",
    "# Add the DATE column into the expanded dataframe with the correct format (the same as our training and testing dataset)\n",
    "##### Continued on the next few cells #####\n",
    "\n",
    "df.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The format of DATES in the training and testing data sets provided by synchrony FINANCIAL are in the for of:\n",
    "#                                                  '01/month/year'\n",
    "# As all other feature data are found with a corresponding DATE with Month being from January (01) ~ December (12)\n",
    "# and Year from 1992 (92) ~ 2017 (17) and with the first day of the month (01).\n",
    "# Thus, the next step is to create a pandas Series object representing the DATE in the corresponding string format\n",
    "\n",
    "# create the month list with strings representing 1 ~ 12 with a '0' prefix\n",
    "month = ['0%d' % s for s in range(1,13) ]\n",
    "# create a new list with the substring constructed by the last two characters in the string to fit the month string \n",
    "# representation in the testin and training data sets and we are done for the month\n",
    "months = [m[-2:] for m in month]\n",
    "months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As above with the month, we do the similar process with the year.\n",
    "# creat a list of string representation of the year with range from 1992 ~ 2017\n",
    "year = [str(y) for y in range(1992, 2018)]\n",
    "# create the years list with the correct format of the year's strings by saving all the year element's substring \n",
    "# constructed by the last two characters of the string\n",
    "years = [y[-2:] for y in year]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DATE list with the same string formats as the training and testing data set\n",
    "# by looping through the months and years list \n",
    "DATE = ['01/%s/%s' % (month, year) for year in years for month in months]\n",
    "# Turn the list into a Pandas Series Object so we can join it with the main dataframe\n",
    "DATE = pd.Series(DATE)\n",
    "# Join the DATE Series with the main dataframe, so the dataframe would have the \"DATE\" column\n",
    "df[\"DATE\"] = DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASPNHSUS</th>\n",
       "      <th>UNRATE</th>\n",
       "      <th>USACPIHOUMINMEI</th>\n",
       "      <th>CSUSHPINSA</th>\n",
       "      <th>MSPNHSUS</th>\n",
       "      <th>MSACSR</th>\n",
       "      <th>MORTGAGE30US</th>\n",
       "      <th>NHFSEPUC</th>\n",
       "      <th>NHSDPC</th>\n",
       "      <th>NHSDPNS</th>\n",
       "      <th>HNFSEPUSSA</th>\n",
       "      <th>HSN1F</th>\n",
       "      <th>DSPIC96</th>\n",
       "      <th>TOTALSA</th>\n",
       "      <th>DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>369200.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>120.448724</td>\n",
       "      <td>194.684</td>\n",
       "      <td>314200.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.880</td>\n",
       "      <td>176.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>559.0</td>\n",
       "      <td>12785.4</td>\n",
       "      <td>16.4</td>\n",
       "      <td>01/08/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>379300.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>120.728451</td>\n",
       "      <td>195.155</td>\n",
       "      <td>331500.0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>3.805</td>\n",
       "      <td>175.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>639.0</td>\n",
       "      <td>12786.9</td>\n",
       "      <td>18.9</td>\n",
       "      <td>01/09/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>394000.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>121.139930</td>\n",
       "      <td>195.430</td>\n",
       "      <td>319500.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>3.895</td>\n",
       "      <td>176.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>616.0</td>\n",
       "      <td>12805.3</td>\n",
       "      <td>18.4</td>\n",
       "      <td>01/10/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>388500.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>121.279407</td>\n",
       "      <td>195.815</td>\n",
       "      <td>343400.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.922</td>\n",
       "      <td>181.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>12814.8</td>\n",
       "      <td>17.9</td>\n",
       "      <td>01/11/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>398700.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>121.604340</td>\n",
       "      <td>196.216</td>\n",
       "      <td>340100.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.950</td>\n",
       "      <td>176.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>653.0</td>\n",
       "      <td>12846.3</td>\n",
       "      <td>18.2</td>\n",
       "      <td>01/12/17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ASPNHSUS  UNRATE  USACPIHOUMINMEI  CSUSHPINSA  MSPNHSUS  MSACSR  \\\n",
       "307  369200.0     4.4       120.448724     194.684  314200.0     6.0   \n",
       "308  379300.0     4.2       120.728451     195.155  331500.0     5.3   \n",
       "309  394000.0     4.1       121.139930     195.430  319500.0     5.6   \n",
       "310  388500.0     4.1       121.279407     195.815  343400.0     4.8   \n",
       "311  398700.0     4.1       121.604340     196.216  340100.0     5.4   \n",
       "\n",
       "     MORTGAGE30US  NHFSEPUC  NHSDPC  NHSDPNS  HNFSEPUSSA  HSN1F  DSPIC96  \\\n",
       "307         3.880     176.0    16.0     13.0       280.0  559.0  12785.4   \n",
       "308         3.805     175.0    17.0     14.0       280.0  639.0  12786.9   \n",
       "309         3.895     176.0    18.0     13.0       286.0  616.0  12805.3   \n",
       "310         3.922     181.0    17.0     16.0       287.0  711.0  12814.8   \n",
       "311         3.950     176.0    19.0     13.0       295.0  653.0  12846.3   \n",
       "\n",
       "     TOTALSA      DATE  \n",
       "307     16.4  01/08/17  \n",
       "308     18.9  01/09/17  \n",
       "309     18.4  01/10/17  \n",
       "310     17.9  01/11/17  \n",
       "311     18.2  01/12/17  "
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with feature data collected in a seasonal matter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We have a few features which are recorded in a seasonal style, thus we will expand them so that the data for each\n",
    "# sesaon would be the same for each months in that season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to work with the Seasonal Data, need to change it into monthly presentation (Each tuple data times three)\n",
    "# We solve it by replicating each row of data 3 times and saving these replicated data into a new list\n",
    "# then transform the list into a pandas Series. This would expand the seasonal data into monthly data.\n",
    "# then we simply join this series into the main dataframe as a new column\n",
    "\n",
    "# change into the directory where the seasonal Data featrues csv data files are located\n",
    "wd = os.path.abspath(\"Seasonal Data to be changed\")\n",
    "# save all the csv files in the files_list\n",
    "files_list = glob.glob( wd + '/*.csv')\n",
    "# read all files into an dataframe and save dataframes to the df_list\n",
    "df_list = [pd.read_csv(file) for file in files_list]\n",
    "# create the data_list where we will put the monthly data expanded by the seasonal data in\n",
    "data_list = []\n",
    "# loop through each of the pandas dataframe to access the feature data Series (all based on the column with index 1)\n",
    "for i in range(len(df_list)):\n",
    "    seasonal_data_series = df_list[i][df_list[i].columns[1]]\n",
    "    # for the data values in these data seriesexpand each of them (appending) 3 times into the data_list\n",
    "    for data in seasonal_data_series:\n",
    "        for expand in range(3):\n",
    "            data_list.append(data)\n",
    "    # create a pandas Series from the data_list\n",
    "    new_data_series = pd.Series(data_list)\n",
    "    # Add the new pandas series into the main dataframe as a new column\n",
    "    df[df_list[i].columns[1]] = new_data_series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe from memory to local disk as \"AllFeaturesData.csv\"\n",
    "df.to_csv(\"AllFeaturesData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# second way of fucking all files together on the columns\n",
    "df = pd.DataFrame()\n",
    "wd = r\"/Users/Roge/Desktop/Datathon\"\n",
    "all_files = glob.glob(wd + '/*.csv')\n",
    "df_list = [pd.read_csv(file) for file in all_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for fileIndex in range(len(df_list)):\n",
    "    df[df_list[fileIndex].columns[1]] = df_list[fileIndex][df_list[fileIndex].columns[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
